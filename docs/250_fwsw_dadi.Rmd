---
title: "FWSW analysis with dadi"
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,out.extra='',fig.pos="H")
knitr::opts_knit$set(root.dir='./fwsw_results/')
```
```{r source}
source("../../gwscaR/R/gwscaR.R")
source("../../gwscaR/R/gwscaR_plot.R")
source("../../gwscaR/R/gwscaR_utility.R")
source("../../gwscaR/R/gwscaR_fsts.R")
source("../../gwscaR/R/gwscaR_popgen.R")
source("../../gwscaR/R/vcf2dadi.R")
library(knitr)
pop.list<-c("ALFW","ALST","FLCC","FLLG","LAFW","TXCC","TXFW")
```

Some useful functions:

```{r dadi.optimal}
parse_dadi_opt<-function(opt.file){
  model.opt<-read.delim(opt.file,sep='\t',header=TRUE,stringsAsFactors = FALSE)
  model.opt$params<-gsub("\\.\\.",",",gsub("optimized_params.(.*)","\\1",colnames(model.opt)[7]))
  colnames(model.opt)[7]<-"optimized_params"
  if(length(grep("Model",model.opt$Model))>0){  #THERE SHOULDN'T BE REPEATED HEADER ROWS
    model.opt<-model.opt[-which(model.opt$Model=="Model"),]
    warning('The model has been run multiple times and output has been concatenated') 
  }
  
  return(model.opt)
}
dadi.optimal<-function(opt.file){
  model.opt<-parse_dadi_opt(opt.file)
  opt<-model.opt[which.max(as.numeric(as.character(model.opt$log.likelihood))),]
  return(opt)
}

```

```{r dadi.modelcomp}
dadi.modelcomp<-function(path,pattern,id){
  opt.files<-list.files(path = path,pattern = pattern,full.names = TRUE)
  #find the best parameter set for each model using maximum log likelihood
  opts<-do.call(rbind,lapply(opt.files,dadi.optimal))
  #rank them by AIC
  opts$rank<-rank(opts$AIC)
  opts$id<-id
  opts<-opts[order(opts$rank),]
  return(opts)
}
```

```{r dadi.nan}
dadi.nan<-function(opt.file){
  model.opt<-read.delim(opt.file,sep='\t',header=TRUE)
  if(length(grep("Model",model.opt$Model))>0){  #THERE SHOULDN'T BE REPEATED HEADER ROWS
    model.opt<-model.opt[-which(model.opt$Model=="Model"),]
    warning('The model has been run multiple times and output has been concatenated') 
  }
  nn<-nrow(model.opt[is.na(model.opt$AIC),])
  nr<-nrow(model.opt)
  return(data.frame(Model=unique(model.opt$Model),NumReps=nr,NumNan=nn))
}
  
```

# Create a dadi SNPs file from the vcf

```{r create_dadi, eval=FALSE}
vcf<-parse.vcf("stacks/populations_subset75/batch_2.vcf")
dadi<-vcf2dadiSNPs(vcf,pop.list = pop.list,filename = "dadi_analysis/fwsw.dadi.snps")
dadi<-read.delim("dadi_analysis/fwsw.dadi.snps")
projections<-unlist(lapply(pop.list,function(pop){ n<-length(grep(pop,colnames(vcf)))}))*2


names(projections)<-pop.list
best.pops<-c("TXFW","TXCB","LAFW","ALST","ALFW","FLLG","FLCC","TXFW ","TXCB ","LAFW ","ALST ","ALFW ","FLLG ","FLCC ")
best.pops<-c("TXFW","TXCB","LAFW","ALST","ALFW","FLLG","FLCC","TXFW.1","TXCB.1","LAFW.1","ALST.1","ALFW.1","FLLG.1","FLCC.1")
dadi<-dadi[,c("Ingroup","Outgroup","Allele1",best.pops[1:7],"Allele2",best.pops[8:14],"GeneID","Position")]
dim(dadi[rowSums(dadi[,colnames(dadi) %in% best.pops])==sum(projections[best.pops[1:7]]),])

#transform this and remove everything but population info for ease of operations
dd<-as.data.frame(cbind(colnames(dadi)[colnames(dadi) %in% best.pops],t(dadi[,colnames(dadi) %in% best.pops])),row.names = 0,stringsAsFactors = FALSE)
#rename the pops to be factors, essentially
dd$V1<-gsub("\\.1","",dd$V1)
#calculate sums per locus for each population
ns<-data.frame(do.call(rbind,lapply(2:ncol(dd),function(c){ tapply(dd[,c],dd$V1,function(x){ sum(as.numeric(x)) }) })))
rownames(ns)<-dadi$GeneID
nozeros<-ns[!(apply(ns, 1, function(y) any(y == 0))),] #512 had zeroes
props<-apply(nozeros,2,function(x) { p<-x/max(x) } )
keepers<-props[apply(props, 1, function(y) any(y >=0.75)),]

#now save these in the dadi format
write.table(dadi[dadi$GeneID %in% rownames(keepers),],"dadi_analysis/fwsw.dadi.pruned.snps",quote=FALSE,row.names = FALSE,
            col.names = c("Ingroup","Outgroup","Allele1","TXFW","TXCB","LAFW","ALST","ALFW","FLLG","FLCC","Allele2","TXFW","TXCB","LAFW","ALST","ALFW","FLLG","FLCC","GeneID","Position"))
```

```{r check_dadis}
vcf.files<-c("stacks/populations_subset50/batch_2.vcf",
             "stacks/populations_subset75/batch_2.vcf",
             #"stacks/populations_subset85/batch_2.vcf",
             #"stacks/populations_subset90/batch_2.vcf",
             #"stacks/populations_subset95/batch_2.vcf",
             "stacks/populations_subset100/batch_2.vcf")

dadis<-lapply(vcf.files,function(file){
  full.vcf<-parse.vcf(file)
  vcf<-choose.one.snp(full.vcf)
  vcf.out.name<-gsub("batch_2.vcf","batch_2.pruned.vcf",file)
  write.table(x = vcf,file = vcf.out.name,quote = FALSE,sep='\t',row.names = FALSE,col.names = TRUE)
  dadi.out<-paste("dadi_analysis/fwsw",gsub(".*populations_subset(\\d+).*","\\1",file),".dadi.snps",sep="")
  pop.list<-c("ALFW","ALST","FLCC","FLLG","LAFW","TXCC","TXFW")
  dadi<-vcf2dadiSNPs(vcf,pop.list = pop.list,filename = dadi.out)
  return(dadi)
})

#compare
kable(cbind(file=vcf.files,numer_snps=unlist(lapply(dadis,nrow))))
```

I'm going to use th 75% of individuals dataset.

## Analyze 1D dadi results

I ran the optimize functions from (dportik's dadi pipeline)[https://github.com/dportik/dadi_pipeline] for each of the 7 populations. Now I need to see what the optimal parameters are (with maximum log likelihood).


```{r}
opt.params<-do.call(rbind,lapply(pop.list, function(pop,dadi.dir="dadi_analysis"){
  if(length(grep("/^",dadi.dir))==0){
    dadi.dir<-paste(dadi.dir,"/",sep="")
  }
  path<-paste(dadi.dir,pop,sep="")
  opts<-dadi.modelcomp(path=path,pattern="optimized")
  return(opts)
}))
write.table(opt.params,"dadi_analysis/1D_optimal_parameters.txt",sep='\t',quote=FALSE,col.names = TRUE,row.names = FALSE)
```
```{r}
opt.params<-read.delim("dadi_analysis/1D_optimal_parameters.txt",header = TRUE)
kable(opt.params)
```



## Analyze 2D FL optimization results


I ran the optimize functions from (dportik's dadi pipeline)[https://github.com/dportik/dadi_pipeline] for a set of 2D demographic models for the Florida populations (FLFW and FLCC):

* Split into two populations, no migration (distributed with `dadi-pipeline`)
* Split into two populations, with continuous symmetric migration (distributed with `dadi-pipeline`)
* Split into two populations, with continuous asymmetric migration (distributed with `dadi-pipeline`)
* Split into two pops, isolation with migration model (distributed with `dadi`)
* Split into two pops, growth in one pop and two epoch in another, no migration (custom model specified in `scripts/250_custom_dadi_models.py`)
* Split into two pops, growth in one pop and two epoch in another, symmetric migration (custom model specified in `scripts/250_custom_dadi_models.py`)
* Split into two pops, growth in one pop and two epoch in another, asymmetric migration (custom model specified in `scripts/250_custom_dadi_models.py`)

At least some of the runs in all of these do not work well (result in "WARNING:Numerics:Extrapolation may have failed. Check resulting frequency spectrum for unexpected results; WARNING:Inference:Model is masked in some entries where data is not"), but the output will tell me more about how frequently it occurs (by parameters showing up as 'nan' instead of values)

Now I need to see what the optimal parameters are for these 7 different runs so that I can run those models for additional iterations and/or compare model fits -- after which I will simulate data with `ms`.

```{r}
fl.opts<-dadi.modelcomp(path = "dadi_analysis/FL2D",pattern=".*optimized.*",id="FL2D")
kable(fl.opts,caption = "'Best' runs of each of the models for the Florida populations 2D demographic inference")
```

This doesn't tell us about which models had trouble converging, though, so let's tally up the number of 'nan's in each file.



```{r}
fl.nans<-do.call(rbind,lapply(list.files(path = "dadi_analysis/FL2D",pattern=".*optimized.*",full.names = TRUE),dadi.nan))
```

Ok, but what about convergence? Are the replicates (Numbers 1-5) converging on likelihoods and parameter values?

```{r}
library(scales)
library(sm)
models<-unique(fl.opts$Model)
par(mfrow=c(3,3))
l<-lapply(models,function(mod){
  files<-list.files(path="dadi_analysis/FL2D",pattern = paste(".*\\.",mod,".optimized.*",sep=""),full.names = TRUE)
  all_reps<-do.call(rbind,lapply(files, parse_dadi_opt))
  lines_per_rep<-nrow(all_reps)/length(files)
  all_reps$rep<-rep(1:length(files),each=lines_per_rep)
  #get the parameter values
  params<-do.call(rbind,lapply(all_reps$optimized_params,function(x){
    p<-as.numeric(as.character(rbind(unlist(strsplit(x,",")))))
    return(p)
  }))
  colnames(params)<-unlist(strsplit(unlist(strsplit(all_reps$params[1],",")),"\\."))
  all_reps<-cbind(all_reps,params)
  
  #plot
  par(xpd=TRUE,mar=c(2,6,2,2))
  plot(0:(ncol(params)*2),xlim=c(0,2*(ncol(params))),ylim=c(min(all_reps$log.likelihood),max(all_reps[,colnames(params)])),bty="L",axes=FALSE,ann=FALSE,type='n')
  gwsca.vioplot(all_reps$log.likelihood,col="grey",add=TRUE,xpd=TRUE,at=0)
  points(jitter(rep(0,nrow(all_reps)),2.5),all_reps$log.likelihood,col=alpha(all_reps$rep,0.5),pch=19)
  axis(2,las=1,pos=-0.5)
  axis(1,lwd=0,label="log likelihood",at=0)
  #mapply(function(param,counts) browser(),colnames(params),2:(ncol(params)+1))
  p<-mapply(function(param,counts){
    par(new=TRUE)
    plot(0:(ncol(params)*2),xlim=c(0,2*(ncol(params))),ylim=c(min(all_reps[,param]),max(all_reps[,param])),bty="L",axes=FALSE,ann=FALSE,type='n')
    gwsca.vioplot(all_reps[,param],col="grey",add=TRUE,xpd=TRUE,ylim=c(min(all_reps[,param]),max(all_reps[,param])),at=counts)
    points(jitter(rep(counts,nrow(all_reps)),2.5),all_reps[,param],col=alpha(all_reps$rep,0.5),pch=19)
    axis(2,las=1,pos=counts-0.75)
    axis(1,lwd=0,label=param,at=counts)
  },colnames(params),seq(2,(ncol(params)*2),by=2))
  mtext(mod,3)
  
})
```


## Analyze 2D TX optimization results


I ran the optimize functions from (dportik's dadi pipeline)[https://github.com/dportik/dadi_pipeline] for a set of 2D demographic models for the Texas populations (TXFW and TXCC):

* Split into two populations, no migration (distributed with `dadi-pipeline`)
* Split into two populations, with continuous symmetric migration (distributed with `dadi-pipeline`)
* Split into two populations, with continuous asymmetric migration (distributed with `dadi-pipeline`)
* Split into two pops, instantaneous size change and no migration (distributed with `dadi-pipeline`)
* Split into two pops, instantaneous size change and continuous symmetric migration (distributed with `dadi-pipeline`)
* Split into two pops with symmetrical gene flow, instantaneous size change and no migration (distributed with `dadi-pipeline`)
* Split into two pops with asymmetrical gene flow, instantaneous size change and no migration (distributed with `dadi-pipeline`)

At least some of the runs in all of these do not work well (result in "WARNING:Numerics:Extrapolation may have failed. Check resulting frequency spectrum for unexpected results; WARNING:Inference:Model is masked in some entries where data is not"), but the output will tell me more about how frequently it occurs (by parameters showing up as 'nan' instead of values)

Now I need to see what the optimal parameters are for these 7 different runs so that I can run those models for additional iterations and/or compare model fits -- after which I will simulate data with `ms`.

```{r}
tx.best<-dadi.modelcomp(path = "dadi_analysis/TX2D",pattern="V2.*optimized.*",id="TX2D")
kable(tx.best,caption = "'Best' runs of each of the models for the Texas populations 2D demographic inference")
```

This doesn't tell us about which models had trouble converging, though, so let's tally up the number of 'nan's in each file.

```{r}
tx.nans<-do.call(rbind,lapply(list.files(path = "dadi_analysis/TX2D",pattern="V2.*optimized.*",full.names = TRUE),dadi.nan))
```

Still not useful, let's extract warning messages from the log file!
```{r}
dadi_warnings<-function(logname){
  log_txt<-scan(logname,what = "character",sep = '\n')
  models<-grep("Model",log_txt[grep("====",log_txt)+1],value = TRUE)
  model_locs<-unique(unlist(lapply(models,grep,x=log_txt)))
  names(model_locs)<-unique(unlist(lapply(models,grep,x=log_txt,value=TRUE)))
  model_locs<-model_locs[order(model_locs)]
  model_locs<-c(model_locs,end=length(log_txt))
  
  prob_reps<-data.frame(Model=NULL,Replicate=NULL)
  for(i in 1:(length(model_locs)-1)){
    prob_rounds<-grep("Round",log_txt[model_locs[i]:model_locs[i+1]][grep("WARNING",log_txt[model_locs[i]:model_locs[i+1]])-1],value=TRUE)
    prob_rep<-gsub(".*(Round) (\\d+) (Replicate) (\\d+) of \\d+:","\\1_\\2_\\3_\\4",prob_rounds)
    prob_reps<-rbind(prob_reps,cbind(Model=gsub("Model (.*)","\\1",names(model_locs[i])),Replicate=prob_rep))
  }
  return(prob_reps)
}

```

```{r}
tx.warnings<-dadi_warnings("dadi_analysis/251_2DTXb.log")
tx.warnings$Warning<-TRUE
tx.opts<-do.call(rbind,lapply(list.files(path = "dadi_analysis/TX2D",pattern="V2.*optimized.*",full.names = TRUE),parse_dadi_opt))
tx.dat<-merge(tx.opts,tx.warnings,by=c("Model","Replicate"),all = TRUE)

```

Do I get vastly different parameter estimates for the ones with warnings?

```{r extractParams}
extract_dadi_params<-function(opt_dat){
  #need to do this separately for each model
  mod_params<-lapply(unique(opt_dat$Model), function(mod){ #browser()
     params<-do.call(rbind,mapply(function(param_est,params){ #browser()
      p<-data.frame(rbind(as.numeric(as.character(rbind(unlist(strsplit(param_est,",")))))))
      colnames(p)<-unlist(strsplit(unlist(strsplit(params,",")),"\\."))
      p<-p[order(colnames(p))]
      p$Model<-mod
      return(p)
    },param_est=opt_dat$optimized_params[opt_dat$Model %in% mod],params=opt_dat$params[opt_dat$Model %in% mod],SIMPLIFY = FALSE))
    this_dat<-cbind(opt_dat[opt_dat$Model %in% mod,],params)
    return(this_dat[-ncol(this_dat)])
  })
  return(mod_params)
}
```
```{r plotParams}

plot_params<-function(dat,params,pt.col="dark grey"){ 
  plot(0:(length(params)*2),xlim=c(0,2*(length(params))),
       ylim=c(min(dat$log.likelihood),max(dat[,params])),
       bty="L",axes=FALSE,ann=FALSE,type='n')
  gwsca.vioplot(dat$log.likelihood,col="grey",add=TRUE,xpd=TRUE,at=0)
  points(jitter(rep(0,nrow(dat)),2.5),dat$log.likelihood,
         col=alpha(pt.col,0.5),pch=19)
  axis(2,las=1,pos=-0.5)
  axis(1,lwd=0,label="log likelihood",at=0)
  #mapply(function(param,counts) browser(),colnames(params),2:(ncol(params)+1))
  p<-mapply(function(param,counts){
    par(new=TRUE)
    plot(0:(length(params)*2),xlim=c(0,2*(length(params))),
         ylim=c(min(dat[,param]),max(dat[,param])),bty="L",axes=FALSE,ann=FALSE,type='n')
    gwsca.vioplot(dat[,param],col="grey",add=TRUE,xpd=TRUE,ylim=c(min(dat[,param]),max(dat[,param])),at=counts)
    points(jitter(rep(counts,nrow(dat)),2.5),dat[,param],col=alpha(pt.col,0.5),pch=19)
    axis(2,las=1,pos=counts-0.75)
    axis(1,lwd=0,label=param,at=counts)
  },params,seq(2,(length(params)*2),by=2))
  mtext(unique(dat$Model),3)
}
```

```{r}
tx_dat<-extract_dadi_params(tx.dat)
par(xpd=TRUE,mar=c(2,6,2,2),mfrow=c(length(tx_dat),2))
pl<-lapply(tx_dat,function(dat){ 
  require(scales)
  require(sm)
  params<-colnames(dat)[(which(colnames(dat)=="Warning")+1):ncol(dat)]
  plot_params(dat[!is.na(dat$Warning),],params,pt.col = "coral")
  legend("topleft",paste("N=",nrow(dat[!is.na(dat$Warning),])),bty='n')
  plot_params(dat[is.na(dat$Warning),],params,pt.col = "grey")
  legend("topleft",paste("N=",nrow(dat[is.na(dat$Warning),])),bty='n')
})


```

What's the best model if I remove ones with warnings?

```{r}
tx.bests<-lapply(tx_dat,function(dat){ 
  keep<-dat[is.na(dat$Warning),]
  best<-keep[which.max(keep$log.likelihood),]
})
tx.bests[[which.min(unlist(lapply(tx.bests,function(x){ return(x$AIC) })))]]
```

Are the multiple rounds improving the model fit?

```{r}
par(xpd=TRUE,mar=c(2,6,2,2),mfrow=c(length(tx_dat),1))
l<-lapply(tx_dat, function(dat){ 
  dat$rounds<-as.numeric(gsub("Round_(\\d+)_Replicate_(\\d+)","\\1",dat$Replicate))
  plot(dat$rounds,dat$log.likelihood,xlab="Round",axes=FALSE,ylab="Log likelihood")
  axis(1,seq(1,4))
  axis(2,las=1)
})
```

Yes they are!


Ok, but what about convergence? Are the replicates (Numbers 1-5) converging on likelihoods and parameter values?

```{r}
library(scales)
library(sm)
models<-unique(tx.opts$Model)
par(mfrow=c(3,3))
l<-lapply(models,function(mod){
  files<-list.files(path="dadi_analysis/TX2D",pattern = paste(".*\\.",mod,".optimized.*",sep=""),full.names = TRUE)
  all_reps<-do.call(rbind,lapply(files, parse_dadi_opt))
  lines_per_rep<-nrow(all_reps)/length(files)
  all_reps$rep<-rep(1:length(files),each=lines_per_rep)
  #get the parameter values
  params<-do.call(rbind,lapply(all_reps$optimized_params,function(x){
    p<-as.numeric(as.character(rbind(unlist(strsplit(x,",")))))
    return(p)
  }))
  colnames(params)<-unlist(strsplit(unlist(strsplit(all_reps$params[1],",")),"\\."))
  all_reps<-cbind(all_reps,params)
  
  #plot
  par(xpd=TRUE,mar=c(2,6,2,2))
  plot(0:(ncol(params)*2),xlim=c(0,2*(ncol(params))),ylim=c(min(all_reps$log.likelihood),max(all_reps[,colnames(params)])),bty="L",axes=FALSE,ann=FALSE,type='n')
  gwsca.vioplot(all_reps$log.likelihood,col="grey",add=TRUE,xpd=TRUE,at=0)
  points(jitter(rep(0,nrow(all_reps)),2.5),all_reps$log.likelihood,col=alpha(all_reps$rep,0.5),pch=19)
  axis(2,las=1,pos=-0.5)
  axis(1,lwd=0,label="log likelihood",at=0)
  #mapply(function(param,counts) browser(),colnames(params),2:(ncol(params)+1))
  p<-mapply(function(param,counts){
    par(new=TRUE)
    plot(0:(ncol(params)*2),xlim=c(0,2*(ncol(params))),ylim=c(min(all_reps[,param]),max(all_reps[,param])),bty="L",axes=FALSE,ann=FALSE,type='n')
    gwsca.vioplot(all_reps[,param],col="grey",add=TRUE,xpd=TRUE,ylim=c(min(all_reps[,param]),max(all_reps[,param])),at=counts)
    points(jitter(rep(counts,nrow(all_reps)),2.5),all_reps[,param],col=alpha(all_reps$rep,0.5),pch=19)
    axis(2,las=1,pos=counts-0.75)
    axis(1,lwd=0,label=param,at=counts)
  },colnames(params),seq(2,(ncol(params)*2),by=2))
  mtext(mod,3)
  
})
```


