---
title: "FWSW analysis with dadi"
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,out.extra='',fig.pos="H")
knitr::opts_knit$set(root.dir='./fwsw_results/')
```
```{r source}
source("../../gwscaR/R/gwscaR.R")
source("../../gwscaR/R/gwscaR_plot.R")
source("../../gwscaR/R/gwscaR_utility.R")
source("../../gwscaR/R/gwscaR_fsts.R")
source("../../gwscaR/R/gwscaR_popgen.R")
source("../../gwscaR/R/vcf2dadi.R")
source("../R/250_dadi_analysis.R")
library(knitr)
pop.list<-c("ALFW","ALST","FLCC","FLLG","LAFW","TXCC","TXFW")
```

Some useful functions are in the `250_dadi_analysis.R` script.

# Create a dadi SNPs file from the vcf

```{r create_dadi, eval=FALSE}
vcf<-parse.vcf("stacks/populations_subset75/batch_2.vcf")
dadi<-vcf2dadiSNPs(vcf,pop.list = pop.list,filename = "dadi_analysis/fwsw.dadi.snps")
dadi<-read.delim("dadi_analysis/fwsw.dadi.snps")
projections<-unlist(lapply(pop.list,function(pop){ n<-length(grep(pop,colnames(vcf)))}))*2


names(projections)<-pop.list
best.pops<-c("TXFW","TXCB","LAFW","ALST","ALFW","FLLG","FLCC","TXFW ","TXCB ","LAFW ","ALST ","ALFW ","FLLG ","FLCC ")
best.pops<-c("TXFW","TXCB","LAFW","ALST","ALFW","FLLG","FLCC","TXFW.1","TXCB.1","LAFW.1","ALST.1","ALFW.1","FLLG.1","FLCC.1")
dadi<-dadi[,c("Ingroup","Outgroup","Allele1",best.pops[1:7],"Allele2",best.pops[8:14],"GeneID","Position")]
dim(dadi[rowSums(dadi[,colnames(dadi) %in% best.pops])==sum(projections[best.pops[1:7]]),])

#transform this and remove everything but population info for ease of operations
dd<-as.data.frame(cbind(colnames(dadi)[colnames(dadi) %in% best.pops],t(dadi[,colnames(dadi) %in% best.pops])),row.names = 0,stringsAsFactors = FALSE)
#rename the pops to be factors, essentially
dd$V1<-gsub("\\.1","",dd$V1)
#calculate sums per locus for each population
ns<-data.frame(do.call(rbind,lapply(2:ncol(dd),function(c){ tapply(dd[,c],dd$V1,function(x){ sum(as.numeric(x)) }) })))
rownames(ns)<-dadi$GeneID
nozeros<-ns[!(apply(ns, 1, function(y) any(y == 0))),] #512 had zeroes
props<-apply(nozeros,2,function(x) { p<-x/max(x) } )
keepers<-props[apply(props, 1, function(y) any(y >=0.75)),]

#now save these in the dadi format
write.table(dadi[dadi$GeneID %in% rownames(keepers),],"dadi_analysis/fwsw.dadi.pruned.snps",quote=FALSE,row.names = FALSE,
            col.names = c("Ingroup","Outgroup","Allele1","TXFW","TXCB","LAFW","ALST","ALFW","FLLG","FLCC","Allele2","TXFW","TXCB","LAFW","ALST","ALFW","FLLG","FLCC","GeneID","Position"))
```

```{r check_dadis}
vcf.files<-c("stacks/populations_subset50/batch_2.vcf",
             "stacks/populations_subset75/batch_2.vcf",
             #"stacks/populations_subset85/batch_2.vcf",
             #"stacks/populations_subset90/batch_2.vcf",
             #"stacks/populations_subset95/batch_2.vcf",
             "stacks/populations_subset100/batch_2.vcf")

dadis<-lapply(vcf.files,function(file){
  full.vcf<-parse.vcf(file)
  vcf<-choose.one.snp(full.vcf)
  vcf.out.name<-gsub("batch_2.vcf","batch_2.pruned.vcf",file)
  write.table(x = vcf,file = vcf.out.name,quote = FALSE,sep='\t',row.names = FALSE,col.names = TRUE)
  dadi.out<-paste("dadi_analysis/fwsw",gsub(".*populations_subset(\\d+).*","\\1",file),".dadi.snps",sep="")
  pop.list<-c("ALFW","ALST","FLCC","FLLG","LAFW","TXCC","TXFW")
  dadi<-vcf2dadiSNPs(vcf,pop.list = pop.list,filename = dadi.out)
  return(dadi)
})

#compare
kable(cbind(file=vcf.files,numer_snps=unlist(lapply(dadis,nrow))))
```

I'm going to use th 75% of individuals dataset.

## Analyze 1D dadi results

I ran the optimize functions from (dportik's dadi pipeline)[https://github.com/dportik/dadi_pipeline] for each of the 7 populations. Now I need to see what the optimal parameters are (with maximum log likelihood).


```{r}
opt.params<-do.call(rbind,lapply(pop.list, function(pop,dadi.dir="dadi_analysis"){
  if(length(grep("/^",dadi.dir))==0){
    dadi.dir<-paste(dadi.dir,"/",sep="")
  }
  path<-paste(dadi.dir,pop,sep="")
  opts<-dadi.modelcomp(path=path,pattern="optimized")
  return(opts)
}))
write.table(opt.params,"dadi_analysis/1D_optimal_parameters.txt",sep='\t',quote=FALSE,col.names = TRUE,row.names = FALSE)
```
```{r}
opt.params<-read.delim("dadi_analysis/1D_optimal_parameters.txt",header = TRUE)
kable(opt.params)
```



## Analyze 2D FL optimization results


I ran the optimize functions from (dportik's dadi pipeline)[https://github.com/dportik/dadi_pipeline] for a set of 2D demographic models for the Florida populations (FLFW and FLCC):

* Split into two populations, no migration (distributed with `dadi-pipeline`)
* Split into two populations, with continuous symmetric migration (distributed with `dadi-pipeline`)
* Split into two populations, with continuous asymmetric migration (distributed with `dadi-pipeline`)
* Split into two pops, isolation with migration model (distributed with `dadi`)
* Split into two pops, growth in one pop and two epoch in another, no migration (custom model specified in `scripts/250_custom_dadi_models.py`)
* Split into two pops, growth in one pop and two epoch in another, symmetric migration (custom model specified in `scripts/250_custom_dadi_models.py`)
* Split into two pops, growth in one pop and two epoch in another, asymmetric migration (custom model specified in `scripts/250_custom_dadi_models.py`)

At least some of the runs in all of these do not work well (result in "WARNING:Numerics:Extrapolation may have failed. Check resulting frequency spectrum for unexpected results; WARNING:Inference:Model is masked in some entries where data is not"), but the output will tell me more about how frequently it occurs (by parameters showing up as 'nan' instead of values)

Now I need to see what the optimal parameters are for these 7 different runs so that I can run those models for additional iterations and/or compare model fits -- after which I will simulate data with `ms`.

```{r}
fl.opts<-dadi.modelcomp(path = "dadi_analysis/FL2D",pattern="V1.*optimized.*",id="FL2D")
kable(fl.opts,caption = "'Best' runs of each of the models for the Florida populations 2D demographic inference")
```

This doesn't tell us about which models had trouble converging, though, so let's tally up the number of 'nan's in each file.

```{r}
fl.nans<-do.call(rbind,lapply(list.files(path = "dadi_analysis/FL2D",pattern="V1.*optimized.*",full.names = TRUE),dadi.nan))
```

How about the ones with warnings? (some of my models did not run, so I'm ignoring those for now. )

```{r}
fl.warnings<-dadi_warnings("dadi_analysis/252_2DFL_V1_1.log",mods=c("Model no_mig","Model sym_mig","Model asym_mig","Model IM"))
fl.warnings$Warning<-TRUE
fl.opts<-do.call(rbind,lapply(list.files(path = "dadi_analysis/FL2D",pattern="V1_Number_1.*[mM].*optimized.*",full.names = TRUE),parse_dadi_opt))
fl.dat<-merge(fl.opts,fl.warnings,by=c("Model","Replicate"),all = TRUE)

```
```{r}
fl.warnings2<-dadi_warnings("dadi_analysis/252_2DFL_V1_2.log")
fl.warnings2$Warning<-TRUE
fl.opts2<-do.call(rbind,lapply(list.files(path = "dadi_analysis/FL2D",pattern="V1_Number_2.*optimized.*",full.names = TRUE),parse_dadi_opt))
fl.dat2<-merge(fl.opts2,fl.warnings2,by=c("Model","Replicate"),all = TRUE)
tapply(fl.warnings2$Warning,fl.warnings2$Model,table)
tapply(fl.warnings$Warning,fl.warnings$Model,table)
```
```{r}
fl.warnings3<-dadi_warnings("dadi_analysis/252_2DFL_V1_3.log")
fl.warnings3$Warning<-TRUE
fl.opts3<-do.call(rbind,lapply(list.files(path = "dadi_analysis/FL2D",pattern="V1_Number_3.*optimized.*",full.names = TRUE),parse_dadi_opt))
fl.dat3<-merge(fl.opts3,fl.warnings3,by=c("Model","Replicate"),all = TRUE)
tapply(fl.warnings3$Warning,fl.warnings3$Model,table)
tapply(fl.warnings2$Warning,fl.warnings2$Model,table)
tapply(fl.warnings$Warning,fl.warnings$Model,table)
```


Most of the warnings come from the IM model. 

```{r}
fl_dat<-extract_dadi_params(rbind(fl.dat,fl.dat2,fl.dat3))
par(xpd=TRUE,mar=c(2,6,2,2),mfrow=c(length(fl_dat),2))
pl<-lapply(fl_dat,function(dat){ 
  require(scales)
  require(sm)
  params<-colnames(dat)[(which(colnames(dat)=="Warning")+1):ncol(dat)]
  plot_params(dat[!is.na(dat$Warning),],params,pt.col = "coral")
  legend("topleft",paste("N=",nrow(dat[!is.na(dat$Warning),])),bty='n')
  plot_params(dat[is.na(dat$Warning),],params,pt.col = "grey")
  legend("topleft",paste("N=",nrow(dat[is.na(dat$Warning),])),bty='n')
})


```

The ones with warnings are pretty bad. What's the best model if I remove ones with warnings?

```{r}
fl.bests<-lapply(fl_dat,function(dat){ 
  keep<-dat[is.na(dat$Warning),]
  best<-keep[which.max(keep$log.likelihood),]
})
fl.bests[[which.min(unlist(lapply(fl.bests,function(x){ return(x$AIC) })))]]
```

I'll use the best parameter estimates to run the next round and see if that helps.

```{r}
par(mfrow=c(3,3))
lapply(fl_dat,function(all_reps){
   par(xpd=TRUE,mar=c(2,6,2,2))
  plot(0:(ncol(params)*2),xlim=c(0,2*(ncol(params))),ylim=c(min(all_reps$log.likelihood),max(all_reps[,colnames(params)])),bty="L",axes=FALSE,ann=FALSE,type='n')
  gwsca.vioplot(all_reps$log.likelihood,col="grey",add=TRUE,xpd=TRUE,at=0)
  points(jitter(rep(0,nrow(all_reps)),2.5),all_reps$log.likelihood,col=alpha(all_reps$rep,0.5),pch=19)
  axis(2,las=1,pos=-0.5)
  axis(1,lwd=0,label="log likelihood",at=0)
  #mapply(function(param,counts) browser(),colnames(params),2:(ncol(params)+1))
  p<-mapply(function(param,counts){
    par(new=TRUE)
    plot(0:(ncol(params)*2),xlim=c(0,2*(ncol(params))),ylim=c(min(all_reps[,param]),max(all_reps[,param])),bty="L",axes=FALSE,ann=FALSE,type='n')
    gwsca.vioplot(all_reps[,param],col="grey",add=TRUE,xpd=TRUE,ylim=c(min(all_reps[,param]),max(all_reps[,param])),at=counts)
    points(jitter(rep(counts,nrow(all_reps)),2.5),all_reps[,param],col=alpha(all_reps$rep,0.5),pch=19)
    axis(2,las=1,pos=counts-0.75)
    axis(1,lwd=0,label=param,at=counts)
  },colnames(params),seq(2,(ncol(params)*2),by=2))
  mtext(mod,3)
})

```



Ok, but what about convergence? Are the replicates (Numbers 1-5) converging on likelihoods and parameter values?


```{r}
library(scales)
library(sm)
models<-unique(fl.opts$Model)
par(mfrow=c(3,3))
l<-lapply(models,function(mod){
  files<-list.files(path="dadi_analysis/FL2D",pattern = paste(".*\\.",mod,".optimized.*",sep=""),full.names = TRUE)
  all_reps<-do.call(rbind,lapply(files, parse_dadi_opt))
  lines_per_rep<-nrow(all_reps)/length(files)
  all_reps$rep<-rep(1:length(files),each=lines_per_rep)
  #get the parameter values
  params<-do.call(rbind,lapply(all_reps$optimized_params,function(x){
    p<-as.numeric(as.character(rbind(unlist(strsplit(x,",")))))
    return(p)
  }))
  colnames(params)<-unlist(strsplit(unlist(strsplit(all_reps$params[1],",")),"\\."))
  all_reps<-cbind(all_reps,params)
  
  #plot
  par(xpd=TRUE,mar=c(2,6,2,2))
  plot(0:(ncol(params)*2),xlim=c(0,2*(ncol(params))),ylim=c(min(all_reps$log.likelihood),max(all_reps[,colnames(params)])),bty="L",axes=FALSE,ann=FALSE,type='n')
  gwsca.vioplot(all_reps$log.likelihood,col="grey",add=TRUE,xpd=TRUE,at=0)
  points(jitter(rep(0,nrow(all_reps)),2.5),all_reps$log.likelihood,col=alpha(all_reps$rep,0.5),pch=19)
  axis(2,las=1,pos=-0.5)
  axis(1,lwd=0,label="log likelihood",at=0)
  #mapply(function(param,counts) browser(),colnames(params),2:(ncol(params)+1))
  p<-mapply(function(param,counts){
    par(new=TRUE)
    plot(0:(ncol(params)*2),xlim=c(0,2*(ncol(params))),ylim=c(min(all_reps[,param]),max(all_reps[,param])),bty="L",axes=FALSE,ann=FALSE,type='n')
    gwsca.vioplot(all_reps[,param],col="grey",add=TRUE,xpd=TRUE,ylim=c(min(all_reps[,param]),max(all_reps[,param])),at=counts)
    points(jitter(rep(counts,nrow(all_reps)),2.5),all_reps[,param],col=alpha(all_reps$rep,0.5),pch=19)
    axis(2,las=1,pos=counts-0.75)
    axis(1,lwd=0,label=param,at=counts)
  },colnames(params),seq(2,(ncol(params)*2),by=2))
  mtext(mod,3)
  
})
```




## Analyze 2D TX optimization results


I ran the optimize functions from (dportik's dadi pipeline)[https://github.com/dportik/dadi_pipeline] for a set of 2D demographic models for the Texas populations (TXFW and TXCC):

* Split into two populations, no migration (distributed with `dadi-pipeline`)
* Split into two populations, with continuous symmetric migration (distributed with `dadi-pipeline`)
* Split into two populations, with continuous asymmetric migration (distributed with `dadi-pipeline`)
* Split into two pops, instantaneous size change and no migration (distributed with `dadi-pipeline`)
* Split into two pops, instantaneous size change and continuous symmetric migration (distributed with `dadi-pipeline`)
* Split into two pops with symmetrical gene flow, instantaneous size change and no migration (distributed with `dadi-pipeline`)
* Split into two pops with asymmetrical gene flow, instantaneous size change and no migration (distributed with `dadi-pipeline`)

At least some of the runs in all of these do not work well (result in "WARNING:Numerics:Extrapolation may have failed. Check resulting frequency spectrum for unexpected results; WARNING:Inference:Model is masked in some entries where data is not"), but the output will tell me more about how frequently it occurs (by parameters showing up as 'nan' instead of values)

Now I need to see what the optimal parameters are for these 7 different runs so that I can run those models for additional iterations and/or compare model fits -- after which I will simulate data with `ms`.

```{r}
tx.best<-dadi.modelcomp(path = "dadi_analysis/TX2D",pattern="V2.*optimized.*",id="TX2D")
kable(tx.best,caption = "'Best' runs of each of the models for the Texas populations 2D demographic inference")
```

This doesn't tell us about which models had trouble converging, though, so let's tally up the number of 'nan's in each file.

```{r}
tx.nans<-do.call(rbind,lapply(list.files(path = "dadi_analysis/TX2D",pattern="V2.*optimized.*",full.names = TRUE),dadi.nan))
```

Still not useful, let's extract warning messages from the log file!

```{r}
tx.warnings<-dadi_warnings("dadi_analysis/251_2DTXb.log")
tx.warnings$Warning<-TRUE
tx.opts<-do.call(rbind,lapply(list.files(path = "dadi_analysis/TX2D",pattern="V2.*optimized.*",full.names = TRUE),parse_dadi_opt))
tx.dat<-merge(tx.opts,tx.warnings,by=c("Model","Replicate"),all = TRUE)

```

Do I get vastly different parameter estimates for the ones with warnings?


```{r}
tx_dat<-extract_dadi_params(tx.dat)
par(xpd=TRUE,mar=c(2,6,2,2),mfrow=c(length(tx_dat),2))
pl<-lapply(tx_dat,function(dat){ 
  require(scales)
  require(sm)
  params<-colnames(dat)[(which(colnames(dat)=="Warning")+1):ncol(dat)]
  plot_params(dat[!is.na(dat$Warning),],params,pt.col = "coral")
  legend("topleft",paste("N=",nrow(dat[!is.na(dat$Warning),])),bty='n')
  plot_params(dat[is.na(dat$Warning),],params,pt.col = "grey")
  legend("topleft",paste("N=",nrow(dat[is.na(dat$Warning),])),bty='n')
})


```

What's the best model if I remove ones with warnings?

```{r}
tx.bests<-lapply(tx_dat,function(dat){ 
  keep<-dat[is.na(dat$Warning),]
  best<-keep[which.max(keep$log.likelihood),]
})
tx.bests[[which.min(unlist(lapply(tx.bests,function(x){ return(x$AIC) })))]]
```

Did a second round with better parameter inputs reduce the warnings?

```{r}
tx.warnings2<-dadi_warnings("dadi_analysis/251_2DTX_V2_2.log")
tx.warnings2$Warning<-TRUE
tx.opts2<-do.call(rbind,lapply(list.files(path = "dadi_analysis/TX2D",pattern="V2.*optimized.*",full.names = TRUE),parse_dadi_opt))
tx.dat2<-merge(tx.opts2,tx.warnings2,by=c("Model","Replicate"),all = TRUE)

```

Nope! The first one had `r nrow(tx.warnings[tx.warnings$Warning=="TRUE",])` and the second had `r nrow(tx.warnings2[tx.warnings2$Warning=="TRUE",])` warnings. I think it might be time to try the other type of model. 

I changed the optimization from `make_extrap_log_func()` to `make_extrap_func()`, which was suggested on the dadi forums.
```{r}
tx.warnings1<-dadi_warnings("dadi_analysis/251_2DTX_V1_1.log")
tx.warnings1$Warning<-TRUE
tx.opts1<-do.call(rbind,lapply(list.files(path = "dadi_analysis/TX2D",pattern="V1.*optimized.*",full.names = TRUE),parse_dadi_opt))
tx.dat1<-merge(tx.opts1,tx.warnings1,by=c("Model","Replicate"),all = TRUE)

```
But this didn't reduce the number of runs with warnings! There were `r dim(tx.warnings1[tx.warnings1$Warning=="TRUE",])` warnings in this run.

```{r}
tapply(tx.warnings1$Warning,tx.warnings1$Model,table)
tapply(tx.warnings2$Warning,tx.warnings2$Model,table)
tapply(tx.warnings$Warning,tx.warnings$Model,table)
```
Unlike the Florida runs, no one model seems to be disproportionately receiving error messages. I should also note that the TX one takes longer to run. Perhaps some of the parameters are simply in a more challenging part of parameter space? To evaluate this, let's look at the best parameters so far

```{r}
tx_dat<-extract_dadi_params(rbind(tx.dat,tx.dat2,tx.dat1))
par(xpd=TRUE,mar=c(2,6,2,2),mfrow=c(length(tx_dat),2))
pl<-lapply(tx_dat,function(dat){ 
  require(scales)
  require(sm)
  params<-colnames(dat)[(which(colnames(dat)=="Warning")+1):ncol(dat)]
  plot_params(dat[!is.na(dat$Warning),],params,pt.col = "coral")
  legend("topleft",paste("N=",nrow(dat[!is.na(dat$Warning),])),bty='n')
  plot_params(dat[is.na(dat$Warning),],params,pt.col = "grey")
  legend("topleft",paste("N=",nrow(dat[is.na(dat$Warning),])),bty='n')
})


```

The ones with warnings are pretty bad and the estimates of nu are all over the place. What's the best model if I remove ones with warnings?

```{r}
tx.bests<-lapply(tx_dat,function(dat){ 
  keep<-dat[is.na(dat$Warning),]
  best<-keep[which.max(keep$log.likelihood),]
})
tx.bests[[which.min(unlist(lapply(tx.bests,function(x){ return(x$AIC) })))]]
```

nu2 estimates seem to be hitting the upper limit that I've set (15), so perhaps that's part of the issue. I'll run another round, increasing the upper limits, increasing the number of points, and updating the starting parameters.


Are the multiple rounds improving the model fit?

```{r}
par(xpd=TRUE,mar=c(2,6,2,2),mfrow=c(length(tx_dat),1))
l<-lapply(tx_dat, function(dat){ 
  dat$rounds<-as.numeric(gsub("Round_(\\d+)_Replicate_(\\d+)","\\1",dat$Replicate))
  plot(dat$rounds,dat$log.likelihood,xlab="Round",axes=FALSE,ylab="Log likelihood")
  axis(1,seq(1,4))
  axis(2,las=1)
})
```

Yes they are!


Ok, but what about convergence? Are the replicates (Numbers 1-5) converging on likelihoods and parameter values?

```{r}
library(scales)
library(sm)
models<-unique(tx.opts$Model)
par(mfrow=c(3,3))
l<-lapply(models,function(mod){
  files<-list.files(path="dadi_analysis/TX2D",pattern = paste(".*\\.",mod,".optimized.*",sep=""),full.names = TRUE)
  all_reps<-do.call(rbind,lapply(files, parse_dadi_opt))
  lines_per_rep<-nrow(all_reps)/length(files)
  all_reps$rep<-rep(1:length(files),each=lines_per_rep)
  #get the parameter values
  params<-do.call(rbind,lapply(all_reps$optimized_params,function(x){
    p<-as.numeric(as.character(rbind(unlist(strsplit(x,",")))))
    return(p)
  }))
  colnames(params)<-unlist(strsplit(unlist(strsplit(all_reps$params[1],",")),"\\."))
  all_reps<-cbind(all_reps,params)
  
  #plot
  par(xpd=TRUE,mar=c(2,6,2,2))
  plot(0:(ncol(params)*2),xlim=c(0,2*(ncol(params))),ylim=c(min(all_reps$log.likelihood),max(all_reps[,colnames(params)])),bty="L",axes=FALSE,ann=FALSE,type='n')
  gwsca.vioplot(all_reps$log.likelihood,col="grey",add=TRUE,xpd=TRUE,at=0)
  points(jitter(rep(0,nrow(all_reps)),2.5),all_reps$log.likelihood,col=alpha(all_reps$rep,0.5),pch=19)
  axis(2,las=1,pos=-0.5)
  axis(1,lwd=0,label="log likelihood",at=0)
  #mapply(function(param,counts) browser(),colnames(params),2:(ncol(params)+1))
  p<-mapply(function(param,counts){
    par(new=TRUE)
    plot(0:(ncol(params)*2),xlim=c(0,2*(ncol(params))),ylim=c(min(all_reps[,param]),max(all_reps[,param])),bty="L",axes=FALSE,ann=FALSE,type='n')
    gwsca.vioplot(all_reps[,param],col="grey",add=TRUE,xpd=TRUE,ylim=c(min(all_reps[,param]),max(all_reps[,param])),at=counts)
    points(jitter(rep(counts,nrow(all_reps)),2.5),all_reps[,param],col=alpha(all_reps$rep,0.5),pch=19)
    axis(2,las=1,pos=counts-0.75)
    axis(1,lwd=0,label=param,at=counts)
  },colnames(params),seq(2,(ncol(params)*2),by=2))
  mtext(mod,3)
  
})
```


