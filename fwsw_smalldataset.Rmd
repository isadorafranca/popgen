---
title: "FWSW with smallest dataset"
output: html_document
author: "Sarah P. Flanagan"
date: "`r format(Sys.time(), '%d %B, %Y')`"
description: "Re-running the freshwater-saltwater analysis using only the dataset from pairwise population comparisons"
---

In my initial analysis of the freshwater-saltwater dataset, I had three vcf files: 
1. one generated from all pairwise comparisons of populations, containing SNPs only found in all 16 populations, in 75% of individuals, and with a minor allele frequency of at least 5%. ("separate")
2. one generated from all pairwise comparisons of populations, containing SNPs found in 4 populations, in 75% of individuals, and with a minor allele frequency of at least 5%. ("P4")
3. one generated from comparing lumped 'freshwater' and 'saltwater' populations, containing SNPs found in 50% of individuals and with a minor allele frequency of at least 5%. ("lumped")

I did the majority of the analyses using set #3, but would like to explore what changes if I use dataset #2. I think #1 is too restrictive. Dataset #2 is in the "subset" dataset, and is what I ran the structure analyses on. This is the dataset I'm going to move forward with for the paper.

Note that in most of these cases the actual analysis will be set to `eval=FALSE` once I've run it once, because then I save the output and only have to read it in, saving compilation time.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir='./fwsw_results/')
```
```{r source}
source("../../gwscaR/R/gwscaR.R")
source("../../gwscaR/R/gwscaR_plot.R")
source("../../gwscaR/R/gwscaR_utility.R")
source("../../gwscaR/R/gwscaR_fsts.R")
source("../../gwscaR/R/gwscaR_popgen.R")
library(knitr)
```

```{r access_analysis, echo=FALSE}
knitr::read_chunk("../scripts/fwsw_analysis.R")
```

```{r FWSWsetup, include=FALSE}
```

```{r pwiseFstsFiles,eval=FALSE}
```

```{r P4plink}
```

This P4/subset dataset has `r nrow(map.sub)` SNPs from `r length(unique(gsub("(\\d+)_\\d+","\\1",map.sub$V2)))` RAD loci, from `r nrow(ped.sub)` indivudals in 16 populations.

## Generate a new vcf file

The first thing to do is to create a vcf file using the subset parameters. I've already got a whitelist of loci in the subsetted dataset, so I need to run `populations -b 2 -W fwsw_results/subset.whitelist.txt -P fwsw_results/stacks -M fwsw_pops_map.txt --vcf`, which I did on 2017-12-18 on silivren-lond. I then re-named it to p4.vcf (and the other output files).


```{r read_vcf}
vcf<-parse.vcf("stacks/p4.vcf") #this is the smaller dataset
```
```{r vcfSetup}
```

The vcf file contains `r nrow(vcf)` SNPs from `r length(unique(vcf$ID))` RAD loci.

Choose a subset of the SNPs to re-use. [Do I need to do this?]

```{r choose_subset} 
chosen.snps<-choose.one.snp(vcf)$SNP
write.table(chosen.snps,"chosen.all.snps.txt",quote=F)
```

```{r read_subset,eval=FALSE}
chosen.snps<-unlist(read.table("chosen.all.snps.txt"))
```

There are `r length(chosen.snps)` SNPs that I'll use from the vcf file, from `r nrow(vcf)` RAD loci.



## Re-running the analysis

I've already run STRUCTURE, adegenet, PCAdapt, pairwise Jost's D, and Fsts on the P4 (or "subset") dataset, so I can just read in those files. Although, since I don't need to re-run STRUCTURE, adegenet, or PCAdapt, I won't read those in. 

```{r readExistingFiles}
jostpw<-read.delim("Subset.JostsD.tsv",sep='\t',header=TRUE,row.names=1)
```
The bayes factors and Fsts are all in the following chunk.
```{r Fig5Files}
```

### Treemix

To run treemix, I follow the following steps:

1. Fit tree without migration
2. Add migration edges using `-m`.
3. Use f3 and f4 ancestry estimation to approximate the amount of admixture and compare to treemix.
4. Use f4 statistics to understand poor fits.

All of these require setting a root, which is FLPB based on previous trees.

First, I need to create a file in the correct format, which uses the vcf file: 

```{r nameTreemix, eval=FALSE}
treemix.name<-"treemix/p4_treemix"
treemix.prefix<-"p4_"
```
```{r generateTreemix, eval=FALSE}
```

Then, in unix, I need to run `gzip -c treemix/p4_treemix > treemix/p4_treemix.gz`. Now I can run `scripts/run_treemix.sh`, which implements steps 1 and 2, and which I need to run in Ubuntu. *Note that there are a lot of "no counts" warnings from treemix. Also, that it runs very quickly*

After that, I can evaluate the different outcomes.

```{r TreemixSetup}
```
```{r FLPBoutgroup}
```
Look at the image and choose a favorite.


```{r define_filenames}
treemix.file<-as.character("treemix/fwsw.basic.cov.gz")#what is 'basic'?
fst.tree.name<-as.character("ALLfst_cov_heatmap.png")
afs.plot.name<-as.character("All_AFS.png")
dd.plot.name<-as.character("separate_delta-divergence.png")
dd.name<-as.character("sep.deltadivergence.txt")
sdd.name<-as.character("sep.smoothedDD.out.txt")
```
I'll run treemix and plotting treemix once I've re-run it.

### PopTree2


**I need to re-run PopTree2**

### Allele Frequency Spectrum
```{r calcAFS,echo=FALSE, eval=FALSE}
```
```{r plotAFS, echo=FALSE, eval=FALSE}
```


### Pi
```{r pi,echo=FALSE, eval=FALSE}
```

### delta-divergence
```{r setupDeltaD,eval=FALSE}
```

